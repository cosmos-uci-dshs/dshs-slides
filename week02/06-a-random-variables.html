<!DOCTYPE html>
<html lang="" xml:lang="">
  <head>
    <title>Probability Distribution</title>
    <meta charset="utf-8" />
    <meta name="author" content="Dr.Â Babak Shahbaba" />
    <script src="libs/header-attrs-2.9/header-attrs.js"></script>
    <link rel="stylesheet" href="slide-style.css" type="text/css" />
  </head>
  <body>
    <textarea id="source">


class: title-slide



&lt;br&gt;
&lt;br&gt;
.right-panel[ 
&lt;br&gt;

# Probability Distribution

### Dr. Babak Shahbaba

]

---

### Random Variables

- In this lecture, we will discuss random variables and their probability distributions.

- Formally, a **random variable** `\(X\)` assigns a
numerical value to each possible outcome (and event) of a random
phenomenon. 

- For instance, we can define `\(X\)` for possible genotypes
of a bi-allelic gene **A** as follows:
`$$X = \left\{ \begin{array}{l@{\quad}l}
0 &amp;  \mbox{for genotype } \mathit{AA}, \\
1 &amp;  \mbox{for genotype } \mathit{Aa}, \\
2 &amp;  \mbox{for genotype } \mathit{aa}.
\end{array} \right.$$`




---

### Random Variables

- After we define a random variable, we can find the probabilities for
its possible values based on the probabilities specified for its underlying
random phenomenon. This way, instead of talking about the probabilities
for different outcomes and events, we can talk about the probability of
different values for a random variable. 

- For example, suppose `\(P({AA}) = 0.49\)`, `\(P({Aa}) = 0.42\)`, and `\(P({aa}) = 0.09\)`. 

- Then, we can say that `\(P(X=0) = 0.49\)`, i.e., `\(X\)` is equal
to `\(0\)` with probability of 0.49. 

- Note that the total probability for the random variable is still 1. 



---

### Random Variables


- The probability distribution of a random variable specifies its
possible values (i.e., its range) and their corresponding
probabilities.

- For the random variable `\(X\)` defined based on genotypes, the
probability distribution can be simply specified as follows:

`$$P(X=x) = \left\{ \begin{array}{l@{\quad}l}
0.49 &amp;  \mbox{for } x=0, \\
0.42 &amp;  \mbox{for } x=1, \\
0.09 &amp;  \mbox{for } x=2.
\end{array} \right.$$`

- Here, `\(x\)` denotes a specific value (i.e., 0, 1, or 2) of the random variable.


---


### Discrete vs. continuous random variables

- We divide the random
variables into two major groups: **discrete** and
**continuous**. 

- Discrete random variables can take a countable set of
values.

- These variables can be categorical (nominal or ordinal), such
as genotype, or counts, such as the number of patients visiting an emergency room per day, 

- Continuous random variables, for example BMI, can take an uncountable number of possible
values.

- For any two possible values of this random variable, we can always find another
value between them. 

---

### Probability distribution

- The probability distribution of a random variable provides the required
information to find the probability of its possible values.

- The probability distributions discussed here are characterized by one or more
**parameters**.

- The parameters of probability distributions we assume for random variables are usually unknown.
- Typically, we use Greek alphabets such as `\(\mu\)` and `\(\sigma\)` to denote these parameters and distinguish them from known values.

- We usually use `\(\mu\)` to denote the mean of a
random variable and use `\(\sigma^{2}\)` to denote its variance.


---

### Discrete probability distributions

- For discrete random variables, the probability distribution is fully
defined by its **probability mass function** (pmf). 

- This is a function that specifies the probability of each possible value within the
range of random variable. 

- For the genotype example, the pmf of the
random variable `\(X\)` is

`$$P(X=x) = \left\{ \begin{array}{l@{\quad}l}
0.49 &amp;  \mbox{for } x=0, \\
0.42 &amp;  \mbox{for } x=1, \\
0.09 &amp;  \mbox{for } x=2.
\end{array} \right.$$`

---

### Continuous probability distributions

- For discrete random variables, the pmf provides the probability of each
possible value. 

- For continuous random variables, the number of possible
values is uncountable, and the probability of any specific value is
zero. 

- For these variables, we are usually interested in the probability that the value of
the random variable is within a specific interval from `\(x_{1}\)` to
`\(x_{2}\)`; we show this probability as `\(P(x_{1} &lt; X \le x_{2})\)`. 


---

### Probability density function

- For continuous random variables, we use **probability density functions** (pdf) to specify the distribution. Using the pdf, we can obtain the probability of any interval. 

&lt;div class="figure" style="text-align: center"&gt;
&lt;img src="img/densityNormalBMI.png" alt="Probability density function for BMI" width="25%" height="60%" /&gt;
&lt;p class="caption"&gt;Probability density function for BMI&lt;/p&gt;
&lt;/div&gt;



---

### Probability density function

- The total area under the probability density curve is 1. 

- The curve (and its corresponding function) gives the probability of the random variable falling within an interval. 

- This probability is equal to the area under the probability density curve over the interval.
&lt;img src="img/densityShaded2530.png" width="25%" height="60%" style="display: block; margin: auto;" /&gt;


---

### Lower tail probability
- the probability of observing
values less than or equal to a specific value `\(x\)`, is called the lower
tail probability and is denoted as `\(P(X \le x)\)`. 

&lt;img src="img/densityShaded18.png" width="25%" height="60%" style="display: block; margin: auto;" /&gt;

---

### Upper tail probability

- The probability of observing values greater than `\(x\)`, `\(P(X &gt; x)\)`, is called the upper tail probability and is found by
measuring the area under the curve to the right of `\(x\)`. 

&lt;img src="img/densityShaded30.png" width="25%" height="60%" style="display: block; margin: auto;" /&gt;

---

### Probability of intervals

- The probability of any interval from `\(x_{1}\)` to `\(x_{2}\)`, where `\(x_{1} &lt; x_{2}\)`, can be obtained using the corresponding lower tail probabilities for these two points as follows:
`$$\begin{equation*}
P(x_1 &lt; X \le x_2) = P(X \le x_2) - P(X \le x_1).
\end{equation*}$$`

- For example, the probability of a BMI between 25 and 30 is
`$$\begin{equation*}
P(25 &lt; X \le 30) = P(X \le 30) - P(X \le 25).
\end{equation*}$$`


---

### Normal distribution

- Consider the probability distribution function and its corresponding probability density curve we assumed for BMI in the above example. 

- This distribution is known as **normal** distribution, which is one of the most widely used distributions for continuous random variables. 

- Random variables with this distribution (or very close to it) occur often in nature.

---

### Normal distribution

- A **normal distribution** and its corresponding pdf are fully specified by the mean `\(\mu\)` and variance `\(\sigma^2\)`. 

- A random variable `\(X\)` with  normal distribution is denoted `\(X \sim N(\mu, \sigma^2)\)`.

- `\(N(0, 1)\)` is called the **standard normal distribution**.
&lt;img src="img/simpNormalDensity.png" width="25%" height="60%" style="display: block; margin: auto;" /&gt;


---

### The 68-95-99.7% rule


- The 68--95--99.7% rule for normal distributions specifies that

  + 68\% of values fall within 1 standard deviation of the mean:
$$ P(\mu-\sigma&lt;X\le\mu+\sigma)=0.68.$$
  + 95\% of values fall within 2 standard deviations of the mean:
`$$P(\mu - 2\sigma &lt; X \le \mu + 2\sigma) = 0.95.$$`

  + 99.7\% of values fall within 3 standard deviations of the mean:
`$$P(\mu - 3\sigma &lt; X \le \mu + 3\sigma) = 0.997.$$`

---

### Normal Distribution

&lt;img src="img/normal68.png" width="40%" height="30%" style="display: block; margin: auto;" /&gt;

---

### Normal Distribution

&lt;img src="img/normal95.png" width="40%" height="49%" style="display: block; margin: auto;" /&gt;


---



### Student's t-distribution

- Another continuous probability distribution that is used very often in
statistics is the **Student's t**-distribution or
simply the `\(t\)`-{distribution}.


&lt;img src="img/standNormT.png" width="30%" height="49%" style="display: block; margin: auto;" /&gt;

---


### Student's t-distribution

- A `\(t\)`-distribution is specified by only one parameter called the
**degrees of freedom** (df). 

- The `\(t\)`-distribution with *df* degrees of freedom is usually denoted as `\(t({df})\)` or `\(t_{df}\)`, where `\(df\)` is a positive real number ( `\(df &gt; 0\)` ). 

- The mean of this distribution is `\(\mu = 0\)`, and
the variance is determined by the degrees of freedom parameter,
`\(\sigma^{2} = df/(df - 2)\)`, which is of course defined when `\(df &gt; 2\)`.

---

### Cumulative distribution function

- We saw that by using lower tail probabilities, we can find the probability of any given interval.

- Indeed, all we need to find the probabilities of any interval is a function that returns the lower tail probability at any given value `\(x\)` of the random variable: `\(P(X \le x)\)`.

- This function is called the **cumulative distribution function** (cdf) or simply the **distribution function**. 

---

### Cumulative distribution function

- We can use the cdf plot to find the lower tail probability for any given value as shown in the following figure. 

&lt;img src="img/standNormCdf.png" width="30%" height="49%" style="display: block; margin: auto;" /&gt;

---

### Quantiles

- We can also use the cdf plot in the reverse direction to find the value of the random variable for a given lower tail probability: quaantiles. 

&lt;img src="img/standNormQuant.png" width="30%" height="49%" style="display: block; margin: auto;" /&gt;

---

### Scaling and shifting random variables

- If `\(Y = a X + b\)`, then

`$$\begin{eqnarray*}
\mu_{Y} &amp; = &amp; a \mu_{X} + b, \\
\sigma^{2}_{Y} &amp; = &amp; a^{2} \sigma^{2}_{X}, \\
\sigma_{Y} &amp; = &amp; |a| \sigma_{X}.
\end{eqnarray*}$$`




---

### Scaling and shifting random variables

- The process of shifting and scaling a random variable to create a new random variable with mean
zero and variance one is called **standardization**. 

- For this, we first subtract the mean `\(\mu\)` and then divide the result by the standard deviation `\(\sigma\)`.
`$$\begin{eqnarray*}
Z = \frac{X - \mu}{\sigma}.
\end{eqnarray*}$$`

- If `\(X \sim N(\mu, \sigma^{2})\)`, then  `\(Z \sim N(0, 1)\)`.


---

### Adding/subtracting random variables

- If `\(W = X + Y\)`, then
`$$\begin{eqnarray*}
\mu_{W} = \mu_{X} + \mu_{Y.}
\end{eqnarray*}$$`

- If the random variables `\(X\)` and `\(Y\)` are independent (i.e., they do not affect each
other probabilities), then we can find the variance of `\(W\)` as follows:
`$$\begin{eqnarray*}
\sigma^{2}_{W} = \sigma^{2}_{X} + \sigma^{2}_{Y}.
\end{eqnarray*}$$`

- If `\(X \sim N(\mu_{X}, \sigma^{2}_{X})\)` and `\(Y \sim N(\mu_{Y}, \sigma^{2}_{Y})\)`, then assuming that the two random variables are
independent, we have
`$$\begin{eqnarray*}
W = X + Y \sim N\bigl(\mu_{X} + \mu_{Y},  \sigma^{2}_{X} +  \sigma^{2}_{Y}\bigr).
\end{eqnarray*}$$`


---

### Adding/subtracting random variables

If we subtract `\(Y\)` from `\(X\)`, then 
`$$\begin{eqnarray*}
\mu_{W} = \mu_{X} - \mu_{Y}.
\end{eqnarray*}$$`

- If the two variables are independent,
`$$\begin{eqnarray*}
\sigma^{2}_{W} = \sigma^{2}_{X} + \sigma^{2}_{Y}.
\end{eqnarray*}$$`

- Note that we still *add* the variances since subtracting `\(Y\)` from `\(X\)` is the same as adding `\(-Y\)` to `\(X\)`. 
    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script>var slideshow = remark.create({
"ratio": "16:9",
"highlightStyle": "pygments",
"highlightLines": true,
"highlightLanguage": "r"
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
(function() {
  "use strict"
  // Replace <script> tags in slides area to make them executable
  var scripts = document.querySelectorAll(
    '.remark-slides-area .remark-slide-container script'
  );
  if (!scripts.length) return;
  for (var i = 0; i < scripts.length; i++) {
    var s = document.createElement('script');
    var code = document.createTextNode(scripts[i].textContent);
    s.appendChild(code);
    var scriptAttrs = scripts[i].attributes;
    for (var j = 0; j < scriptAttrs.length; j++) {
      s.setAttribute(scriptAttrs[j].name, scriptAttrs[j].value);
    }
    scripts[i].parentElement.replaceChild(s, scripts[i]);
  }
})();
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
// adds .remark-code-has-line-highlighted class to <pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
  const hlines = d.querySelectorAll('.remark-code-line-highlighted');
  const preParents = [];
  const findPreParent = function(line, p = 0) {
    if (p > 1) return null; // traverse up no further than grandparent
    const el = line.parentElement;
    return el.tagName === "PRE" ? el : findPreParent(el, ++p);
  };

  for (let line of hlines) {
    let pre = findPreParent(line);
    if (pre && !preParents.includes(pre)) preParents.push(pre);
  }
  preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
