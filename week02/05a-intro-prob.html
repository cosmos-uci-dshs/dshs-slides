<!DOCTYPE html>
<html lang="" xml:lang="">
  <head>
    <title>Introduction to Probability</title>
    <meta charset="utf-8" />
    <meta name="author" content="Dr.Â Babak Shahbaba" />
    <script src="libs/header-attrs-2.9/header-attrs.js"></script>
    <link rel="stylesheet" href="slide-style.css" type="text/css" />
  </head>
  <body>
    <textarea id="source">


class: title-slide



&lt;br&gt;
&lt;br&gt;
.right-panel[ 
&lt;br&gt;

# Introduction to Probability

### Dr. Babak Shahbaba

]

---

class: middle

### Introduction
 - We have used plots and summary statistics to learn about the distribution of different variables in the observed data and to investigate their relationships. 
 
 - We now want to **generalize** our findings to the entire population of interest. 
 
 - However, we almost always remain uncertain about the true distributions and relationships in the population.
 
 - Therefore, when we generalize our findings from a sample to the whole population, we should explicitly specify the extent of our uncertainty.  
 
 - We use probability as a measure of our uncertainty.
 
 
---
 
### Some Commonly Used Genetic Terms

- Throughout this lecture, we will use the following concepts from genetics:  

  - Gene

  - Single Nucleotide Polymorphisms (SNPs)

  - Alleles

  - Genotype

  - Homozygous vs. heterozygous

  - Phenotype

  - Recessive vs. dominant

---

### Random phenomena and their sample space

- A phenomenon is called random if its outcome (value) cannot be determined with certainty before it occurs. 

- For example, coin tossing and genotypes  are random phenomena.

- The collection of all possible outcomes `\(S\)` is called the sample space. 
`$$\begin{array}{l@{\quad}l}
\text{Coin tossing:}  &amp; S=\{H, T\}, \\
\text{Die rolling:} &amp;  S=\{1, 2, 3, 4, 5, 6\}, \\
\text{Bi-allelic gene:} &amp; S=\{A,a\},\\
\text{Genotype:} &amp; S=\{\mathit{AA}, \mathit{Aa}, \mathit{aa}\}.
\end{array}$$`
---

### Probability

- To each possible outcome in the sample space, we assign a probability `\(P\)`, which represents how certain we are about the occurrence of the corresponding outcome. 

- For an outcome `\(o\)`, we denote the probability as `\(P(o)\)`, where `\(0 \le P(o) \le 1\)`. 

- The total probability of all outcomes in the sample space is always 1.

  - Coin tossing: `\(P(H)+ P(T)=1\)`
  - Die rolling:  `\(P(1)+P(2)+P(3)+P(4)+P(5)+P(6) = 1\)`.

- Therefore, if the outcomes are equally probable, the probability of
each outcome is `\(1/n_{S}\)`, where `\(n_{S}\)` is the number of possible
outcomes.
  
---

### Random events

- An **event** is a subset of the sample space `\(S\)`. 

- A possible event for die rolling is `\(E = \{1, 3, 5\}\)`. This is the event of rolling an
odd number. 

- For the genotype example, `\(E=\{\mathit{AA}, \mathit{aa}\}\)`
is the event that a person is homozygous.

- An event occurs when any outcome within that event occurs. 

- We denote the probability of event `\(E\)` as `\(P(E)\)`.
 
- The probability of an event is the sum of the probabilities for all
individual outcomes included in that event.

---

### Example

- As a running example, we consider a bi-allelic gene A with
two alleles `\(A\)` and `\(a\)`. 

- We assume that allele `\(a\)` is recessive and
causes a specific disease. 

- Then only people with the genotype
`\(\mathit{aa}\)` have the disease. 

&lt;img src="img/vennGene1.png" width="50%" style="display: block; margin: auto;" /&gt;

---

### Example
- We can define four events as follows:
`$$\begin{array}{l@{\quad}l}
\text{The homozygous event:} &amp; HM = \{\mathit{AA}, \mathit{aa}\}, \\
\text{The heterozygous event:} &amp; HT  = \{\mathit{Aa}\},  \\  
\text{The no-disease event:} &amp; ND   = \{\mathit{AA}, \mathit{Aa}\}, \\
\text{The disease event:} &amp; D   = \{\mathit{aa}\} .
\end{array}$$`
- Assume `\(P(\mathit{AA}) = 0.49\)`,
`\(P(\mathit{Aa}) = 0.42\)`, and `\(P(\mathit{aa}) = 0.09\)`. Then,
$$
`\begin{eqnarray*}
P(HM ) &amp; = &amp; 0.49+0.09 = 0.58,  \\
P(HT ) &amp; = &amp; 0.42, \\
P(ND) &amp; = &amp; 0.49 + 0.42 = 0.91,\\
P(D) &amp; = &amp; 0.09.
\end{eqnarray*}`
$$
---

### Complement
- For any event `\(E\)`, we define its **complement**, `\(E^c\)`, as the set
of all outcomes that are in the sample space `\(S\)` but not in `\(E\)`.

- For the gene-disease example, the complement of the homozygous event
`\(HM  = \{\mathit{AA}, \mathit{aa}\}\)` is the heterozygous event
`\(\{\mathit{Aa}\}\)`; we show this as `\(HM^{c} = HT\)`. 

- Likewise, the complement of the disease event, `\(D=\{\mathit{aa}\}\)`, is the no-disease
event, `\(ND = \{\mathit{AA}, \mathit{Aa}\}\)`; we show this as `\(D^{c} = ND\)`.

- The probability of the complement event is 1 minus the probability of
the event:
`$$P\bigl(E^{c}\bigr) = 1- P(E).$$`


---

### Union

- For two events `\(E_{1}\)` and `\(E_{2}\)` in a sample space `\(S\)`, we define
their **union** `\(E_{1}\cup E_{2}\)` as the set of all outcomes that
are at least in one of the events. 

- The union `\(E_{1}\cup E_{2}\)` is an
event by itself, and it occurs when **either** `\(E_{1}\)` **or**
`\(E_{2}\)` (or both) occurs. 

- For example, the
union of the heterozygous event, `\(HT\)`, and the disease event, `\(D\)`, is
`\(\{\mathit{Aa}\} \cup \{\mathit{aa}\} = \{\mathit{Aa}, \mathit{aa}\}\)`.

- When possible, we can identify the outcomes in the
union of the two events and find the probability by adding the
probabilities of those outcomes.

---


### Intersection

- For two events `\(E_{1}\)` and `\(E_{2}\)` in a sample space `\(S\)`, we define their **intersection** `\(E_{1} \cap E_{2}\)` as the set of outcomes that are in **both** events. 

- The intersection `\(E_{1}\cap E_{2}\)` is an event
by itself, and it occurs when both `\(E_{1}\)` **and** `\(E_{2}\)` occur.

- The intersection of
the homozygous event and the no-disease event is `\(HM  \cap ND = \{\mathit{AA}\}\)`.

- When possible, we can identify the outcomes in the
intersection of the two events and find the probability by adding the
probabilities of those outcomes.

---

### Joint vs. marginal probability
- We refer to the probability of the intersection of two events, `\(P(E_{1} \cap E_{2})\)`, as their **joint probability**. 

- In contrast, we refer to probabilities `\(P(E_{1})\)` and `\(P(E_{2})\)` as the **marginal probabilities** of events `\(E_{1}\)` and `\(E_{2}\)`.

- For any two events `\(E_{1}\)` and `\(E_{2}\)`, we have

`$$P(E_{1} \cup E_{2}) = P(E_{1}) + P(E_{2}) - P(E_{1} \cap E_{2}).$$`
- That is, the probability of the union `\(P(E_1 \cup E_2)\)` is the sum of their marginal probabilities minus their joint probability. 

---

### Joint vs. marginal probability

- For example, the union of the heterozygous and the no-disease events is
`$$\begin{eqnarray*}
P(HM  \cup ND)  &amp;=&amp;  P(HM ) + P(ND) - P(HM  \cap ND) \\
  &amp;= &amp; 0.58 + 0.91 - 0.49 = 1.
\end{eqnarray*}$$`

---

### Disjoint events
- Two events are called **disjoint** or **mutually exclusive** if they never occur together: if we know that one of them has occurred,
we can conclude that the other event has~not. 

- Disjoint events have no
elements (outcomes) in common, and their intersection is the empty set.

- For the above example, if a person is heterozygous, we know that he does not have the disease so the two events `\(HT\)` and `\(ND\)` are disjoint. 


---

### Disjoint events

- For two disjoint events `\(E_{1}\)` and `\(E_{2}\)`, the probability of their
intersection (i.e., their joint probability) is zero: 
`$$P(E_{1} \cap E_{2}) = P(\phi) =  0$$`
- Therefore, the probability of the union of the two disjoint events is simply the sum of their marginal probabilities: 
`$$P(E_{1} \cup E_{2}) = P(E_{1}) + P(E_{2})$$`
- In general, if we have multiple disjoint events, `\(E_1\)`, `\(E_2\)`, ..., `\(E_n\)`, then the probability of their union is the sum of the marginal probabilities:
`$$P(E_1 \cup E_2 \cup ... \cup E_n) = P(E_1) + P(E_2) + ... + P(E_n)$$`

---

### Partition

- When two or more events are disjoint and their union is the sample
space `\(S\)`, we say that the events form a **partition** of the
sample space.

- Two complementary events `\(E\)` and `\(E^{c}\)` always form a partition of the
sample space since they are disjoint and their union is the sample
space.

---

### Conditional probability

- Ver often, we need to discuss possible changes in the
probability of one event based on our knowledge regarding the
occurrence of another event.

- The **conditional probability**, denoted  `\(P(E_{1}|E_{2})\)`, is the
probability of event `\(E_1\)` given that another event `\(E_2\)` has occurred.

- The conditional probability of event `\(E_1\)` given event `\(E_2\)` can be
calculated as follows: (assuming `\(P(E_{2}) \ne 0\)`)

`$$P(E_{1}|E_{2}) = \frac{P(E_{1} \cap E_{2})}{P(E_{2})}.$$`

- This is the joint probability of the two events divided
by the marginal probability of the event on which we are conditioning.


---

### The law of total probability

- By rearranging the equation for conditional probabilities, we have
`$$P(E_{1} \cap E_{2}) = P(E_{1}|E_{2})P(E_{2}).$$`

- Now suppose that a set of `\(K\)` events `\(B_1, B_2, \ldots, B_K\)` forms a
partition of the sample space.
&lt;img src="img/generalPartition.png" width="50%" style="display: block; margin: auto;" /&gt;

---

### The law of total probability

- Using the above equation, we have
`$$P(A)  =  P(A|B_{1})P(B_{1}) + \cdots + P(A|B_{K})P(B_{K}).$$`
- This is known as the **law of total probability**.



---

### Independent events

- Two events `\(E_{1}\)` and `\(E_{2}\)` are **independent** if our
knowledge of the occurrence of one event does not change the
probability of occurrence of the other event. 

`\begin{eqnarray*}
P(E_{1}|E_{2}) &amp; = &amp; P(E_{1}), \\
P(E_{2}|E_{1}) &amp; = &amp; P(E_{2}).
\end{eqnarray*}`

- For example, if a disease is not genetic, knowing a person has a specific genotype (e.g., `\(AA\)`) does not  change the probability of having that disease. 

---

### Independent events

- When two events `\(E_{1}\)` and `\(E_{2}\)` are independent, the probability
that `\(E_{1}\)` and `\(E_{2}\)` occur simultaneously, i.e., their joint
probability, is the product of their marginal probabilities:

`$$P(E_{1} \cap E_{2}) = P(E_{1})\times P(E_{2})$$`

- Therefore, the probability of the union of two independent events is as follows:
`$$P(E_{1} \cup E_{2}) = P(E_{1}) + P(E_{2}) - P(E_{1}) \times P(E_{2}).$$`


---

### Bayes' theorem

- Sometimes, we know the conditional
probability of `\(E_{1}\)` given `\(E_{2}\)`, but we are interested in the
conditional probability of `\(E_{2}\)` given `\(E_{1}\)`. 

- For example, suppose
that the probability of having lung cancer is `\(P(C) = 0.001\)` and that
the probability of being a smoker is `\(P(SM) = 0.25\)`. 

- Further, suppose
we know that if a person has lung cancer, the probability of being a
smoker increases to `\(P(SM |C) = 0.40\)`.  

- We are, however, interested in
the probability of developing lung cancer if a person is a smoker,
`\(P(C|SM)\)`. 


---

### Bayes' theorem

- In general, for two events `\(E_1\)` and `\(E_2\)`, the following equation
shows the relationship between `\(P(E_{2}|E_{1})\)` and `\(P(E_{1}|E_{2})\)`:
`$$P(E_{2}|E_{1})  =  \frac{P(E_{1}|E_{2})P(E_{2})}{P(E_{1})}.$$`

- This formula is known as **Bayes' theorem** or **Bayes' rule**.

---

### Bayes' theorem

- For the above example, 
`$$P(C|SM)  =  \frac{P(SM|C)P(C) }{P(SM)} = \frac{ 0.4 \times 0.001}{0.25} = 0.0016.$$`

- Therefore, the probability of lung cancer for smokers increases from
0.001 to 0.0016. 


---

### Diagnostic tests


- Diagnostic tests provide an interesting example of Bayes' theorem. 
- The following figure from Baldi and Utts (2015) summarizes a typical screening process: 
&lt;img src="img/baldiUtts3.png" width="55%" style="display: block; margin: auto;" /&gt;

---

### Diagnostic tests

- We can summarize different scenarios as follows:

&lt;img src="img/SensitivitySpecificity.png" width="80%" style="display: block; margin: auto;" /&gt;

---

### Diagnostic tests

- Based on this table, we have

`$$\begin{eqnarray*}
\textrm{Sensitivity} &amp; = &amp; P(\textrm{Positive} | \textrm{Disease} )\\
\textrm{Specificity} &amp; = &amp; P(\textrm{Negative} | \textrm{No Disease})\\
\textrm{Positive Predictive Value (PPV)} &amp; = &amp; P(\textrm{Disease} | \textrm{Positive})
\end{eqnarray*}$$`

- Using Bayes' theorem, we have:
`$$\begin{eqnarray*}
\textrm{PPV} &amp; = &amp; \frac{\textrm{prevalence} \times \textrm{sensitivity} }{\textrm{prevalence} \times \textrm{sensitivity}+ \textrm{(1- prevalence)} \times \textrm{(1- specificity)}}
\end{eqnarray*}$$`
where *prevalence* is the overall probability of the disease in the population: `\(P(Disease)\)` 
    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script>var slideshow = remark.create({
"ratio": "16:9",
"highlightStyle": "pygments",
"highlightLines": true,
"highlightLanguage": "r"
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
(function() {
  "use strict"
  // Replace <script> tags in slides area to make them executable
  var scripts = document.querySelectorAll(
    '.remark-slides-area .remark-slide-container script'
  );
  if (!scripts.length) return;
  for (var i = 0; i < scripts.length; i++) {
    var s = document.createElement('script');
    var code = document.createTextNode(scripts[i].textContent);
    s.appendChild(code);
    var scriptAttrs = scripts[i].attributes;
    for (var j = 0; j < scriptAttrs.length; j++) {
      s.setAttribute(scriptAttrs[j].name, scriptAttrs[j].value);
    }
    scripts[i].parentElement.replaceChild(s, scripts[i]);
  }
})();
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
// adds .remark-code-has-line-highlighted class to <pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
  const hlines = d.querySelectorAll('.remark-code-line-highlighted');
  const preParents = [];
  const findPreParent = function(line, p = 0) {
    if (p > 1) return null; // traverse up no further than grandparent
    const el = line.parentElement;
    return el.tagName === "PRE" ? el : findPreParent(el, ++p);
  };

  for (let line of hlines) {
    let pre = findPreParent(line);
    if (pre && !preParents.includes(pre)) preParents.push(pre);
  }
  preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
